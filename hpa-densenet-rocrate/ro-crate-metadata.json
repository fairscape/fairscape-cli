{
  "@context": {
    "@vocab": "https://schema.org/",
    "EVI": "https://w3id.org/EVI#"
  },
  "@graph": [
    {
      "@id": "ro-crate-metadata.json",
      "@type": "CreativeWork",
      "conformsTo": {
        "@id": "https://w3id.org/ro/crate/1.2"
      },
      "about": {
        "@id": "ark:59852/rocrate-hpa-densenet-image-classification-fp5xla0gnqk"
      }
    },
    {
      "@id": "ark:59852/rocrate-hpa-densenet-image-classification-fp5xla0gnqk",
      "@type": [
        "Dataset",
        "https://w3id.org/EVI#ROCrate"
      ],
      "name": "HPA DenseNet Image Classification",
      "description": "RO-Crate containing the HPA DenseNet model for subcellular protein localization classification. This model was developed as part of the Human Protein Atlas Image Classification competition on Kaggle, which aimed to develop deep learning solutions for multi-label classification of protein subcellular localization patterns in confocal microscopy images. The winning solution achieved a macro F1 score of 0.593, outperforming previous methods by ~20%.",
      "keywords": [
        "deep learning",
        "image classification",
        "protein localization",
        "Human Protein Atlas",
        "DenseNet",
        "subcellular localization",
        "confocal microscopy",
        "multi-label classification",
        "Kaggle competition"
      ],
      "isPartOf": [
        {
          "@id": "ark:59852/organization-human-protein-atlas-4tCR6LBOxj"
        },
        {
          "@id": "ark:59852/project-hpa-image-classification-competition-wGpIm4qfpCf"
        }
      ],
      "version": "1.0",
      "hasPart": [
        {
          "@id": "ark:59852/model-timm-densenet121-tvin1k-acvgvkftyu"
        },
        {
          "@id": "ark:59852/dataset-imagenet-1k-ilsvrc2012-ukaldydlgo"
        },
        {
          "@id": "ark:59852/computation-densenet121-training-on-imagenet-1k-1OtA8FB7G3"
        },
        {
          "@id": "ark:59852/dataset-human-protein-atlas-subcellular-localization-images-tsmhx5lyfzm"
        },
        {
          "@id": "ark:59852/computation-hpa-densenet-classification-model-training-W7OKQwh0Esx"
        },
        {
          "@id": "ark:59852/model-hpa-densenet-subcellular-localization-classifier-karpzsrkpl"
        },
        {
          "@id": "ark:59852/computation-hpa-densenet-classification-model-training-W7OKQwh0Esx"
        }
      ],
      "author": "Wei Ouyang, Casper F. Winsnes, Martin Hjelmare, Anthony J. Cesnik, Emma Lundberg et al.",
      "license": "https://creativecommons.org/licenses/by/4.0/",
      "associatedPublication": "https://doi.org/10.1038/s41592-019-0658-6",
      "datePublished": "2026-01-08"
    },
    {
      "@id": "ark:59852/model-timm-densenet121-tvin1k-acvgvkftyu",
      "name": "timm/densenet121.tv_in1k",
      "@type": [
        "prov:Entity",
        "https://w3id.org/EVI#MLModel"
      ],
      "author": "timm",
      "description": "DenseNet-121 model pretrained on ImageNet-1k. DenseNet (Densely Connected Convolutional Networks) connects each layer to every other layer in a feed-forward fashion. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. This architecture alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, and substantially reduces the number of parameters. This specific variant is from the torchvision implementation trained on ImageNet-1k with 1000 classes.",
      "version": "1.0",
      "contentUrl": "https://huggingface.co/timm/densenet121.tv_in1k/resolve/main/model.safetensors",
      "isPartOf": [],
      "usedByComputation": [],
      "prov:wasGeneratedBy": [],
      "prov:wasDerivedFrom": [
        {
          "@id": "https://huggingface.co/datasets/imagenet-1k"
        }
      ],
      "prov:wasAttributedTo": [
        "timm"
      ],
      "keywords": [
        "timm",
        "pytorch",
        "safetensors",
        "image-classification",
        "transformers",
        "dataset:imagenet-1k",
        "arxiv:1608.06993",
        "license:apache-2.0",
        "region:us"
      ],
      "modelType": "Convolutional Neural Network",
      "framework": "PyTorch",
      "trainingDataset": [
        {
          "@id": "https://huggingface.co/datasets/imagenet-1k"
        }
      ],
      "derivedFrom": [
        {
          "@id": "https://huggingface.co/datasets/imagenet-1k"
        }
      ],
      "intendedUseCase": "Image classification, feature extraction, transfer learning for biological image analysis",
      "usageInformation": "Can be used as a pretrained backbone for downstream tasks including protein subcellular localization classification",
      "url": "https://huggingface.co/timm/densenet121.tv_in1k",
      "license": "apache-2.0",
      "format": "safetensors",
      "README": "# Model card for densenet121.tv_in1k\n\nA DenseNet image classification model. Trained on ImageNet-1k (original torchvision weights).\n\n## Model Details\n- **Model Type:** Image classification / feature backbone\n- **Model Stats:**\n  - Params (M): 8.0\n  - GMACs: 2.9\n  - Activations (M): 6.9\n  - Image size: 224 x 224\n- **Papers:**\n  - Densely Connected Convolutional Networks: https://arxiv.org/abs/1608.06993\n- **Dataset:** ImageNet-1k\n- **Original:** https://github.com/pytorch/vision\n\n## Model Usage\n### Image Classification\n```python\nfrom urllib.request import urlopen\nfrom PIL import Image\nimport timm\n\nimg = Image.open(urlopen(\n    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'\n))\n\nmodel = timm.create_model('densenet121.tv_in1k', pretrained=True)\nmodel = model.eval()\n\n# get model specific transforms (normalization, resize)\ndata_config = timm.data.resolve_model_data_config(model)\ntransforms = timm.data.create_transform(**data_config, is_training=False)\n\noutput = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n\ntop5_probabilities, top5_class_indices = torch.topk(output.softmax(dim=1) * 100, k=5)\n```\n\n### Feature Map Extraction\n```python\nfrom urllib.request import urlopen\nfrom PIL import Image\nimport timm\n\nimg = Image.open(urlopen(\n    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'\n))\n\nmodel = timm.create_model(\n    'densenet121.tv_in1k',\n    pretrained=True,\n    features_only=True,\n)\nmodel = model.eval()\n\n# get model specific transforms (normalization, resize)\ndata_config = timm.data.resolve_model_data_config(model)\ntransforms = timm.data.create_transform(**data_config, is_training=False)\n\noutput = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n\nfor o in output:\n    # print shape of each feature map in output\n    # e.g.:\n    #  torch.Size([1, 64, 112, 112])\n    #  torch.Size([1, 256, 56, 56])\n    #  torch.Size([1, 512, 28, 28])\n    #  torch.Size([1, 1024, 14, 14])\n    #  torch.Size([1, 1024, 7, 7])\n\n    print(o.shape)\n```\n\n### Image Embeddings\n```python\nfrom urllib.request import urlopen\nfrom PIL import Image\nimport timm\n\nimg = Image.open(urlopen(\n    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'\n))\n\nmodel = timm.create_model(\n    'densenet121.tv_in1k',\n    pretrained=True,\n    num_classes=0,  # remove classifier nn.Linear\n)\nmodel = model.eval()\n\n# get model specific transforms (normalization, resize)\ndata_config = timm.data.resolve_model_data_config(model)\ntransforms = timm.data.create_transform(**data_config, is_training=False)\n\noutput = model(transforms(img).unsqueeze(0))  # output is (batch_size, num_features) shaped tensor\n\n# or equivalently (without needing to set num_classes=0)\n\noutput = model.forward_features(transforms(img).unsqueeze(0))\n# output is unpooled, a (1, 1024, 7, 7) shaped tensor\n\noutput = model.forward_head(output, pre_logits=True)\n# output is a (1, num_features) shaped tensor\n```\n\n## Citation\n```bibtex\n@inproceedings{huang2017densely,\n  title={Densely Connected Convolutional Networks},\n  author={Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q },\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n  year={2017}\n}\n```\n"
    },
    {
      "@id": "ark:59852/dataset-imagenet-1k-ilsvrc2012-ukaldydlgo",
      "name": "ImageNet-1k (ILSVRC2012)",
      "@type": [
        "prov:Entity",
        "https://w3id.org/EVI#Dataset"
      ],
      "author": "Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, Li Fei-Fei",
      "description": "ImageNet Large Scale Visual Recognition Challenge 2012 (ILSVRC2012) dataset, commonly known as ImageNet-1k. Contains 1,281,167 training images, 50,000 validation images, and 100,000 test images across 1,000 object categories. The dataset is widely used for training and benchmarking image classification models. Images are variable size with typical dimensions around 469x387 pixels. Each image is labeled with one of 1000 synset categories derived from WordNet. This dataset was used to pretrain the DenseNet121 model that serves as the base for the HPA classification model.",
      "version": "1.0.0",
      "associatedPublication": "https://doi.org/10.1007/s11263-015-0816-y",
      "additionalDocumentation": "https://www.image-net.org/challenges/LSVRC/2012/",
      "contentUrl": "https://huggingface.co/datasets/ILSVRC/imagenet-1k",
      "isPartOf": [],
      "usedByComputation": [],
      "prov:wasGeneratedBy": [],
      "prov:wasDerivedFrom": [],
      "prov:wasAttributedTo": [
        "Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, Li Fei-Fei"
      ],
      "additionalType": "Dataset",
      "datePublished": "2012-01-01",
      "keywords": [
        "ImageNet",
        "ILSVRC",
        "image classification",
        "benchmark dataset",
        "computer vision",
        "deep learning",
        "object recognition"
      ],
      "format": "JPEG images",
      "generatedBy": [],
      "derivedFrom": [],
      "url": "https://image-net.org/"
    },
    {
      "@id": "ark:59852/computation-densenet121-training-on-imagenet-1k-1OtA8FB7G3",
      "name": "DenseNet121 Training on ImageNet-1k",
      "@type": [
        "prov:Activity",
        "https://w3id.org/EVI#Computation"
      ],
      "description": "Training computation for DenseNet-121 model on ImageNet-1k dataset. The model was trained using the torchvision implementation with standard ImageNet training procedures including data augmentation (random resized crop, horizontal flip), SGD optimizer with momentum, and learning rate scheduling. Training was performed on GPU hardware. The resulting model achieves competitive top-1 and top-5 accuracy on the ImageNet validation set.",
      "generated": [
        {
          "@id": "ark:59852/model-timm-densenet121-tvin1k-acvgvkftyu"
        }
      ],
      "isPartOf": [],
      "prov:used": [
        {
          "@id": "ark:59852/dataset-imagenet-1k-ilsvrc2012-ukaldydlgo"
        }
      ],
      "prov:wasAssociatedWith": [
        "Ross Wightman (timm library)"
      ],
      "additionalType": "Computation",
      "runBy": "Ross Wightman (timm library)",
      "dateCreated": "2019-01-01",
      "additionalDocumentation": "https://github.com/huggingface/pytorch-image-models",
      "usedSoftware": [],
      "usedMLModel": [],
      "usedDataset": [
        {
          "@id": "ark:59852/dataset-imagenet-1k-ilsvrc2012-ukaldydlgo"
        }
      ],
      "keywords": [
        "model training",
        "deep learning",
        "ImageNet",
        "DenseNet",
        "PyTorch"
      ]
    },
    {
      "@id": "ark:59852/dataset-human-protein-atlas-subcellular-localization-images-tsmhx5lyfzm",
      "name": "Human Protein Atlas Subcellular Localization Images",
      "@type": [
        "prov:Entity",
        "https://w3id.org/EVI#Dataset"
      ],
      "author": "Human Protein Atlas Consortium, Emma Lundberg, Mathias Uhlen",
      "description": "Immunofluorescence microscopy image dataset from the Human Protein Atlas Cell Atlas project. The dataset contains confocal microscopy images mapping subcellular protein localization across 27 human cell lines. Each image has four channels: protein of interest (green), microtubules (red), nucleus (blue), and endoplasmic reticulum (yellow). Images are annotated with 28 subcellular localization classes including nucleoplasm, cytosol, plasma membrane, mitochondria, Golgi apparatus, and others. The competition dataset consisted of 42,774 images (31,072 training, 11,702 test) with multi-label annotations (1-6 labels per image). The dataset exhibits high class imbalance, with nucleoplasm being the most common label (12,885 images) and rods and rings being the rarest (11 images). Image dimensions are typically 2048x2048 or 3072x3072 pixels at 16-bit depth with 0.08 um pixel size.",
      "version": "18.0",
      "associatedPublication": "https://doi.org/10.1126/science.aal3321",
      "additionalDocumentation": "https://www.proteinatlas.org/humanproteome/subcellular",
      "contentUrl": "https://www.kaggle.com/c/human-protein-atlas-image-classification/data",
      "isPartOf": [],
      "usedByComputation": [],
      "prov:wasGeneratedBy": [],
      "prov:wasDerivedFrom": [],
      "prov:wasAttributedTo": [
        "Human Protein Atlas Consortium, Emma Lundberg, Mathias Uhlen"
      ],
      "additionalType": "Dataset",
      "datePublished": "2018-10-03",
      "keywords": [
        "Human Protein Atlas",
        "subcellular localization",
        "immunofluorescence",
        "confocal microscopy",
        "protein imaging",
        "cell biology",
        "multi-label classification",
        "proteomics"
      ],
      "format": "TIFF/PNG images",
      "generatedBy": [],
      "derivedFrom": [],
      "url": "https://www.proteinatlas.org/about/download"
    },
    {
      "@id": "ark:59852/computation-hpa-densenet-classification-model-training-W7OKQwh0Esx",
      "name": "HPA DenseNet Classification Model Training",
      "@type": [
        "prov:Activity",
        "https://w3id.org/EVI#Computation"
      ],
      "description": "Training computation for the winning HPA Image Classification model. The solution used DenseNet-121 as the backbone architecture, pretrained on ImageNet-1k, and fine-tuned on the HPA subcellular localization dataset. Key techniques employed: (1) Combined loss function with Lovasz loss term for multi-label classification, (2) Cyclical learning rates for optimization, (3) AutoAugment data augmentation strategy, (4) Large image size training (1024x1024 pixels), (5) Model ensembling. The training utilized both the competition dataset (31,072 images) and the public HPAv18 dataset (~78,000 images) to improve performance on rare classes. The final model achieved a macro F1 score of 0.593 on the private test set, winning first place among 2,172 teams. Training was performed on GPU hardware using PyTorch framework.",
      "associatedPublication": "https://doi.org/10.1038/s41592-019-0658-6",
      "generated": [],
      "isPartOf": [],
      "prov:used": [
        {
          "@id": "ark:59852/dataset-human-protein-atlas-subcellular-localization-images-tsmhx5lyfzm"
        },
        {
          "@id": "ark:59852/dataset-imagenet-1k-ilsvrc2012-ukaldydlgo"
        }
      ],
      "prov:wasAssociatedWith": [
        "Shubin Dai (Team bestfitting, Kaggle Competition Winner)"
      ],
      "additionalType": "Computation",
      "runBy": "Shubin Dai (Team bestfitting, Kaggle Competition Winner)",
      "dateCreated": "2019-01-10",
      "additionalDocumentation": "https://github.com/CellProfiling/HPA-competition",
      "usedSoftware": [],
      "usedMLModel": [],
      "usedDataset": [
        {
          "@id": "ark:59852/dataset-human-protein-atlas-subcellular-localization-images-tsmhx5lyfzm"
        },
        {
          "@id": "ark:59852/dataset-imagenet-1k-ilsvrc2012-ukaldydlgo"
        }
      ],
      "keywords": [
        "transfer learning",
        "fine-tuning",
        "multi-label classification",
        "Kaggle competition",
        "DenseNet",
        "Lovasz loss",
        "AutoAugment",
        "image classification"
      ]
    },
    {
      "@id": "ark:59852/model-hpa-densenet-subcellular-localization-classifier-karpzsrkpl",
      "name": "HPA DenseNet Subcellular Localization Classifier",
      "@type": [
        "prov:Entity",
        "https://w3id.org/EVI#MLModel"
      ],
      "author": "Shubin Dai (Team bestfitting)",
      "description": "Winning model from the Human Protein Atlas Image Classification Kaggle competition. This DenseNet-121 based model classifies protein subcellular localization patterns in immunofluorescence microscopy images into 28 cellular compartment classes. The model handles the challenging multi-label classification problem where proteins can localize to multiple compartments simultaneously (1-6 labels per image). Key features: (1) DenseNet-121 backbone pretrained on ImageNet-1k, (2) Modified for 4-channel input (protein, microtubules, nucleus, ER), (3) Combined loss function with Lovasz loss for multi-label optimization, (4) Trained with AutoAugment data augmentation, (5) Input size of 1024x1024 pixels. The model achieved a macro F1 score of 0.593, representing a >20% improvement over previous methods (Loc-CAT: 0.47) and approaching expert human performance (0.71). The learned features can be used for image classification, pattern similarity measurement via feature extraction, or as pretrained weights for other biological imaging applications.",
      "version": "1.0",
      "associatedPublication": "https://doi.org/10.1038/s41592-019-0658-6",
      "contentUrl": "https://modelzoo.cellprofiling.org",
      "isPartOf": [],
      "usedByComputation": [],
      "prov:wasGeneratedBy": [
        {
          "@id": "ark:59852/computation-hpa-densenet-classification-model-training-W7OKQwh0Esx"
        }
      ],
      "prov:wasDerivedFrom": [
        {
          "@id": "ark:59852/dataset-human-protein-atlas-subcellular-localization-images-tsmhx5lyfzm"
        }
      ],
      "prov:wasAttributedTo": [
        "Shubin Dai (Team bestfitting)"
      ],
      "keywords": [
        "DenseNet",
        "protein localization",
        "multi-label classification",
        "Human Protein Atlas",
        "subcellular localization",
        "deep learning",
        "confocal microscopy",
        "transfer learning",
        "Kaggle winner"
      ],
      "modelType": "Convolutional Neural Network (DenseNet-121)",
      "framework": "PyTorch",
      "trainingDataset": [
        {
          "@id": "ark:59852/dataset-human-protein-atlas-subcellular-localization-images-tsmhx5lyfzm"
        }
      ],
      "generatedBy": {
        "@id": "ark:59852/computation-hpa-densenet-classification-model-training-W7OKQwh0Esx"
      },
      "derivedFrom": [
        {
          "@id": "ark:59852/dataset-human-protein-atlas-subcellular-localization-images-tsmhx5lyfzm"
        }
      ],
      "inputSize": "1024x1024x4 (RGBY channels: protein, microtubules, nucleus, ER)",
      "intendedUseCase": "Classification of protein subcellular localization patterns in immunofluorescence microscopy images. Can also be used for feature extraction to measure pattern similarity or as pretrained weights for biological image analysis tasks.",
      "usageInformation": "Input: 4-channel confocal microscopy images (green=protein, red=microtubules, blue=nucleus, yellow=ER). Output: Multi-label predictions for 28 subcellular localization classes with confidence scores. Recommended preprocessing: resize to 1024x1024, normalize to 8-bit.",
      "baseModel": "ark:59852/model-timm-densenet121-tvin1k-acvgvkftyu",
      "url": "https://modelzoo.cellprofiling.org",
      "license": "https://creativecommons.org/licenses/by/4.0/",
      "citation": "Ouyang, W., Winsnes, C.F., Hjelmare, M. et al. Analysis of the Human Protein Atlas Image Classification competition. Nat Methods 16, 1254-1261 (2019). https://doi.org/10.1038/s41592-019-0658-6",
      "format": "PyTorch checkpoint"
    },
    {
      "@id": "ark:59852/computation-hpa-densenet-classification-model-training-W7OKQwh0Esx",
      "name": "HPA DenseNet Classification Model Training",
      "@type": [
        "prov:Activity",
        "https://w3id.org/EVI#Computation"
      ],
      "description": "Training computation for the winning HPA Image Classification model. The solution used DenseNet-121 as the backbone architecture, pretrained on ImageNet-1k, and fine-tuned on the HPA subcellular localization dataset. Key techniques employed: (1) Combined loss function with Lovasz loss term for multi-label classification, (2) Cyclical learning rates for optimization, (3) AutoAugment data augmentation strategy, (4) Large image size training (1024x1024 pixels), (5) Model ensembling. The training utilized both the competition dataset (31,072 images) and the public HPAv18 dataset (~78,000 images) to improve performance on rare classes. The final model achieved a macro F1 score of 0.593 on the private test set, winning first place among 2,172 teams. Training was performed on GPU hardware using PyTorch framework.",
      "associatedPublication": "https://doi.org/10.1038/s41592-019-0658-6",
      "generated": [
        {
          "@id": "ark:59852/model-hpa-densenet-subcellular-localization-classifier-karpzsrkpl"
        }
      ],
      "isPartOf": [],
      "prov:used": [
        {
          "@id": "ark:59852/dataset-human-protein-atlas-subcellular-localization-images-tsmhx5lyfzm"
        },
        {
          "@id": "ark:59852/dataset-imagenet-1k-ilsvrc2012-ukaldydlgo"
        }
      ],
      "prov:wasAssociatedWith": [
        "Shubin Dai (Team bestfitting, Kaggle Competition Winner)"
      ],
      "additionalType": "Computation",
      "runBy": "Shubin Dai (Team bestfitting, Kaggle Competition Winner)",
      "dateCreated": "2019-01-10",
      "additionalDocumentation": "https://github.com/CellProfiling/HPA-competition",
      "usedSoftware": [],
      "usedMLModel": [],
      "usedDataset": [
        {
          "@id": "ark:59852/dataset-human-protein-atlas-subcellular-localization-images-tsmhx5lyfzm"
        },
        {
          "@id": "ark:59852/dataset-imagenet-1k-ilsvrc2012-ukaldydlgo"
        }
      ],
      "keywords": [
        "transfer learning",
        "fine-tuning",
        "multi-label classification",
        "Kaggle competition",
        "DenseNet",
        "Lovasz loss",
        "AutoAugment",
        "image classification"
      ]
    }
  ]
}